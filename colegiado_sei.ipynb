{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import os\n",
    "#from bs4 import BeautifulSoup\n",
    "#import re\n",
    "#from collections import OrderedDict\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "#import getpass\n",
    "import pyshorteners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login realizado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "def realizar_login(url, login1, password1, orgao1):\n",
    "    \"\"\"\n",
    "    Função para realizar login no sistema SEI.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL do sistema SEI.\n",
    "        login1 (str): Nome de usuário para login.\n",
    "        password1 (str): Senha para login.\n",
    "        orgao1 (str): Nome do órgão para acesso.\n",
    "\n",
    "    Returns:\n",
    "        webdriver: Instância do WebDriver com o usuário autenticado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Inicializa o navegador\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.implicitly_wait(0.5)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Localiza os elementos de login\n",
    "        login = driver.find_element(By.XPATH, '//*[@id=\"txtUsuario\"]')\n",
    "        password = driver.find_element(By.XPATH, '//*[@id=\"pwdSenha\"]')\n",
    "        orgao = driver.find_element(By.XPATH, '//*[@id=\"selOrgao\"]')\n",
    "        submit_button = driver.find_element(By.XPATH, '//*[@id=\"Acessar\"]')\n",
    "\n",
    "        # Preenche as credenciais\n",
    "        login.send_keys(login1)\n",
    "        password.send_keys(password1)\n",
    "        orgao.send_keys(orgao1)\n",
    "\n",
    "        # Realiza o login\n",
    "        submit_button.click()\n",
    "        time.sleep(3)  # Aguarda carregamento da página após o login\n",
    "\n",
    "        print(\"Login realizado com sucesso!\")\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao realizar o login: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "url = 'https://sei.economia.gov.br/'\n",
    "login1 = 'daiana.sales@gestao.gov.br'\n",
    "password1 = \"Div&rtidam&nt&081099\"\n",
    "orgao1 = \"MGI\"\n",
    "\n",
    "# Realiza login\n",
    "driver = realizar_login(url, login1, password1, orgao1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searching = driver.find_element(By.XPATH, '//*[@id=\"infraMenu\"]/li[14]/a/span')\n",
    "searching.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionar os pesquisar em documentos\n",
    "docum_pesq = driver.find_element(By.XPATH, '//*[@id=\"divOptDocumentos\"]/div')\n",
    "docum_pesq.click()\n",
    "time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecionar pesquisar em processos\n",
    "process = driver.find_element(By.XPATH, '//*[@id=\"divOptProcessos\"]/div')\n",
    "process.click()\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer busca através dos documentos, clicar no botão considerar documentos\n",
    "cons_doc = driver.find_element(By.XPATH, '//*[@id=\"divSinConsiderarDocumentos\"]/div')\n",
    "cons_doc.click()\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colocar como tramitação dentro do orgão\n",
    "chktram = driver.find_element(By.XPATH, '//*[@id=\"divSinTramitacao\"]/div')\n",
    "chktram.click()\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifica os termos de pesquisa\n",
    "espec_pesq = driver.find_element(By.XPATH, '//*[@id=\"q\"]')\n",
    "espec_pesq.send_keys('indicação ou retificação ou nomear ou nomeação ou ratificar ou retificar ou representante ou exoneração')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restringe busca ao órgão específico\n",
    "# sel_orgao = driver.find_element(By.XPATH, '//*[@id=\"divSinRestringirOrgao\"]/div')\n",
    "# sel_orgao.click()\n",
    "# time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restringe busca ao órgão específico\n",
    "# sel_orgao = driver.find_element(By.XPATH, '//*[@id=\"divSinRestringirOrgao\"]/div')\n",
    "# sel_orgao.click()\n",
    "# time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar pesquisa por tipo de processo\n",
    "tipo_process = driver.find_element(By.XPATH, '//*[@id=\"selTipoProcedimentoPesquisa\"]')\n",
    "tipo_process.send_keys(\"Gestão Administrativa: Conselhos, Comissões, Comitês, Grupos de Trabalho e Juntas\")\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a pesquisa\n",
    "b_pesq = driver.find_element(By.XPATH, '//*[@id=\"sbmPesquisar\"]')\n",
    "b_pesq.click()\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_process = driver.find_element(By.XPATH, '//*[@id=\"conteudo\"]/table/tbody/tr[1]/td[1]/a[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal para busca\n",
    "def buscar_arquivos(driver):\n",
    "    \"\"\"\n",
    "    Realiza a busca de arquivos no sistema SEI após login.\n",
    "\n",
    "    Args:\n",
    "        driver (webdriver): Instância do WebDriver autenticada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "                        \n",
    "        # Acessa a área de busca\n",
    "        searching = driver.find_element(By.XPATH, '//*[@id=\"infraMenu\"]/li[14]/a/span')\n",
    "        searching.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # selecionar os processos\n",
    "        process = driver.find_element(By.XPATH, '//*[id=\"divOptProcessos\"]/div')\n",
    "        process.click()\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        #fazer busca através dos documentos, clicar no botão considerar documentos\n",
    "        cons_doc = driver.find_element(By.XPATH, '//*[@id=\"divSinConsiderarDocumentos\"]/div')\n",
    "        cons_doc.click()\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # #colocar como tramitação dentro do orgão\n",
    "        # chktram = driver.find_element(By.XPATH, '//*[id=\"chkSinTramitacao\"]/div')\n",
    "        # chktram.click()\n",
    "        # time.sleep(0.2)\n",
    "\n",
    "        # # Restringe busca ao órgão específico\n",
    "        # sel_orgao = driver.find_element(By.XPATH, '//*[@id=\"divSinRestringirOrgao\"]/div')\n",
    "        # sel_orgao.click()\n",
    "        # time.sleep(0.5)\n",
    "\n",
    "        # Especifica os termos de pesquisa\n",
    "        espec_pesq = driver.find_element(By.XPATH, '//*[@id=\"q\"]')\n",
    "        espec_pesq.send_keys('indicação ou retificação ou nomear ou nomeação ou ratificar ou retificar ou representante ou exoneração')\n",
    "        \n",
    "        # Realizar pesquisa por tipo de processo\n",
    "        tipo_process = driver.find_element(By.XPATH, '//*[@id=\"selTipoProcedimentoPesquisa\"]')\n",
    "        tipo_process.send_keys(\"Gestão Administrativa: Conselhos, Comissões, Comitês, Grupos de Trabalho e Juntas\")\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # # colocar datas\n",
    "        # data_inicio = driver.find_element('xpath', '//*[@id=\"txtDataInicio\"]')\n",
    "        # data_inicio.send_keys(\"01/09/2024\")\n",
    "        # time.sleep(0.5)\n",
    "        \n",
    "        # Realiza a pesquisa\n",
    "        b_pesq = driver.find_element(By.XPATH, '//*[@id=\"sbmPesquisar\"]')\n",
    "        b_pesq.click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        print(\"Busca realizada com sucesso.\\nRestringindo em PL e dentro do MGI.\\n\\nOs Externo entram como MGI.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro durante a busca: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro durante a busca: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[id=\"divOptProcessos\"]/div\"}\n",
      "  (Session info: chrome=131.0.6778.265); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7DEFF80D5+2992373]\n",
      "\t(No symbol) [0x00007FF7DEC8BFD0]\n",
      "\t(No symbol) [0x00007FF7DEB2590A]\n",
      "\t(No symbol) [0x00007FF7DEB7926E]\n",
      "\t(No symbol) [0x00007FF7DEB7955C]\n",
      "\t(No symbol) [0x00007FF7DEBC27D7]\n",
      "\t(No symbol) [0x00007FF7DEB9F3AF]\n",
      "\t(No symbol) [0x00007FF7DEBBF584]\n",
      "\t(No symbol) [0x00007FF7DEB9F113]\n",
      "\t(No symbol) [0x00007FF7DEB6A918]\n",
      "\t(No symbol) [0x00007FF7DEB6BA81]\n",
      "\tGetHandleVerifier [0x00007FF7DF056A2D+3379789]\n",
      "\tGetHandleVerifier [0x00007FF7DF06C32D+3468109]\n",
      "\tGetHandleVerifier [0x00007FF7DF060043+3418211]\n",
      "\tGetHandleVerifier [0x00007FF7DEDEC78B+847787]\n",
      "\t(No symbol) [0x00007FF7DEC9757F]\n",
      "\t(No symbol) [0x00007FF7DEC92FC4]\n",
      "\t(No symbol) [0x00007FF7DEC9315D]\n",
      "\t(No symbol) [0x00007FF7DEC82979]\n",
      "\tBaseThreadInitThunk [0x00007FFC73FA7344+20]\n",
      "\tRtlUserThreadStart [0x00007FFC75AE26B1+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se o login foi bem-sucedido, realiza a busca\n",
    "if driver:\n",
    "    buscar_arquivos(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados1(driver):     \n",
    "    \"\"\"\n",
    "    Função para realizar web scraping no SEI e retornar os dados em um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        driver (webdriver): Instância do Selenium WebDriver.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os dados extraídos.\n",
    "    \"\"\"\n",
    "    def remove_items(lista, item): \n",
    "        \"\"\"Remove todos os itens iguais a `item` de uma lista.\"\"\"\n",
    "        return [i for i in lista if i != item]\n",
    "\n",
    "    # Extraindo os elementos da pesquisa\n",
    "    tree_elements = driver.find_elements(\"xpath\", '//*[@class=\"protocoloNormal\"]/a')\n",
    "    list_tree = [element.text for element in tree_elements]\n",
    "    trees = remove_items(list_tree, '')  # Remover elementos vazios\n",
    "\n",
    "    # abts = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaSnippet\"]')\n",
    "    # list_abts = [element.text for element in abts]\n",
    "\n",
    "    unidades = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaMetatag\"]')\n",
    "    list_uni = [element.text.split(':') for element in unidades]\n",
    "    info = [sublist_uni[1] for sublist_uni in list_uni if len(sublist_uni) > 1]  # Removendo listas vazias\n",
    "\n",
    "    rows = driver.find_elements(\"xpath\", '//*[@id=\"conteudo\"]/table/tbody/tr')\n",
    "    links = []\n",
    "    \n",
    "    for i in range(1, len(rows), 3):\n",
    "        try:\n",
    "            a = driver.find_element(\"xpath\", f'//*[@id=\"conteudo\"]/table/tbody/tr[{i}]/td[1]/a[2]')\n",
    "            time.sleep(0.5)\n",
    "            link = a.get_attribute('href')\n",
    "            print(link)\n",
    "            time.sleep(0.5)\n",
    "            links.append(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar a linha {i}: {e}\")\n",
    "\n",
    "    shortener = pyshorteners.Shortener(api_key='your_api_key', provider='isgd')\n",
    "    links_curtos = []\n",
    "    erros = []\n",
    "    \n",
    "    for link in links:\n",
    "        try:\n",
    "            # Verificando o tamanho do link antes de encurtar\n",
    "            if len(link) > 1000:  # Ajuste o limite conforme necessário\n",
    "                raise ValueError(f\"Link muito longo: {link}\")\n",
    "            link_curto = shortener.tinyurl.short(link)\n",
    "            time.sleep(0.5)\n",
    "            links_curtos.append(link_curto)\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            erros.append((link, str(e)))\n",
    "            links_curtos.append(None)\n",
    "\n",
    "    dados = {\n",
    "        \"Número do Processo\": trees[::2],\n",
    "        \"Documento\": trees[1::2],\n",
    "        # \"Resumo\": list_abts,\n",
    "        \"Unidade\": info[::3],\n",
    "        \"Usuário\": info[1::3],\n",
    "        \"Data de Inclusão\": info[2::3],\n",
    "        \"Links\": links_curtos\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(dados)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados(driver):     \n",
    "    \"\"\"\n",
    "    Função para realizar web scraping no SEI e retornar os dados em um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        driver (webdriver): Instância do Selenium WebDriver.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os dados extraídos.\n",
    "    \"\"\"\n",
    "    def remove_items(lista, item): \n",
    "        \"\"\"Remove todos os itens iguais a `item` de uma lista.\"\"\" \n",
    "        return [i for i in lista if i != item]\n",
    "\n",
    "    # Extraindo os elementos da pesquisa\n",
    "    tree_elements = driver.find_elements(\"xpath\", '//*[@class=\"protocoloNormal\"]/a')\n",
    "    list_tree = [element.text for element in tree_elements]\n",
    "    trees = remove_items(list_tree, '')  # Remover elementos vazios\n",
    "\n",
    "    unidades = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaMetatag\"]')\n",
    "    list_uni = [element.text.split(':') for element in unidades]\n",
    "    info = [sublist_uni[1] for sublist_uni in list_uni if len(sublist_uni) > 1]  # Removendo listas vazias\n",
    "\n",
    "    rows = driver.find_elements(\"xpath\", '//*[@id=\"conteudo\"]/table/tbody/tr')\n",
    "    links = []\n",
    "    \n",
    "    for i in range(1, len(rows), 3):\n",
    "        try:\n",
    "            a = driver.find_element(\"xpath\", f'//*[@id=\"conteudo\"]/table/tbody/tr[{i}]/td[1]/a[2]')\n",
    "            time.sleep(0.5)\n",
    "            link = a.get_attribute('href')\n",
    "            # print(link)\n",
    "            time.sleep(0.5)\n",
    "            links.append(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar a linha {i}: {e}\")\n",
    "\n",
    "    # Inicializando o encurtador de links\n",
    "    shortener = pyshorteners.Shortener(api_key='your_api_key', provider='isgd')\n",
    "    links_curtos = []\n",
    "    erros = []\n",
    "    \n",
    "    for link in links:\n",
    "        try:\n",
    "            # Separando a parte fixa e o hash do link\n",
    "            base_url, hash_value = link.split('infra_hash=')\n",
    "            \n",
    "            # Verificando o tamanho da parte fixa do link antes de encurtar\n",
    "            if len(base_url) > 1000:  # Ajuste o limite conforme necessário\n",
    "                raise ValueError(f\"Link base muito longo: {base_url}\")\n",
    "            \n",
    "            # Encurtando a parte fixa do link\n",
    "            link_curto = shortener.tinyurl.short(base_url)\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            # Recriando o link com o hash\n",
    "            link_com_hash = link_curto + 'infra_hash=' + hash_value\n",
    "            \n",
    "            links_curtos.append(link_com_hash)\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            erros.append((link, str(e)))\n",
    "            links_curtos.append(None)\n",
    "\n",
    "    # Organizando os dados para o DataFrame\n",
    "    dados = {\n",
    "        \"Número do Processo\": trees[::2],\n",
    "        \"Documento\": trees[1::2],\n",
    "        # \"Resumo\": list_abts,  # Caso esteja disponível\n",
    "        \"Unidade\": info[::3],\n",
    "        \"Usuário\": info[1::3],\n",
    "        \"Data de Inclusão\": info[2::3],\n",
    "        \"Links\": links_curtos\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(dados)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"conteudo\"]/table/tbody/tr[1]/td[1]/a[2]\n",
    "//*[@id=\"conteudo\"]/table/tbody/tr[4]/td[1]/a[2]\n",
    "//*[@id=\"conteudo\"]/table/tbody/tr[7]/td[1]/a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"conteudo\"]/div[2]/div[3]/a\n",
    "//*[@id=\"conteudo\"]/div[2]/div[2]/a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"eeca66fc03ffc04ef6fd26c06df9878b\", element=\"f.5E6FC65D48D26A7FBFBC5FF83EED7B81.d.1CF8FA24881A9A0B6F4A559D6E5B03BE.e.772\")>\n"
     ]
    }
   ],
   "source": [
    "next_page = driver.find_element(\"xpath\", '//*[@id=\"conteudo\"]/div[2]/div[3]/a')\n",
    "print(next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript:navegar('10')\n"
     ]
    }
   ],
   "source": [
    "proxima_href = next_page.get_attribute('href')\n",
    "print(proxima_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749', 'https://tinyurl.com/2268fmdqinfra_hash=98c74b0b38ca33ec7b6a01440a9243ab5eb9b3c414504a78adb24078eec818a0']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749', 'https://tinyurl.com/2268fmdqinfra_hash=98c74b0b38ca33ec7b6a01440a9243ab5eb9b3c414504a78adb24078eec818a0', 'https://tinyurl.com/264j5aa6infra_hash=67100b0ab7a52ad8e5d365a7a036711626ee457dbb7de12cda2bcfcbd865a3a1']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749', 'https://tinyurl.com/2268fmdqinfra_hash=98c74b0b38ca33ec7b6a01440a9243ab5eb9b3c414504a78adb24078eec818a0', 'https://tinyurl.com/264j5aa6infra_hash=67100b0ab7a52ad8e5d365a7a036711626ee457dbb7de12cda2bcfcbd865a3a1', 'https://tinyurl.com/245dqwsginfra_hash=a2fbcc1a7a0aa9191c8820c570c97d86796c45543783a89cefb3f877fd0c5155']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749', 'https://tinyurl.com/2268fmdqinfra_hash=98c74b0b38ca33ec7b6a01440a9243ab5eb9b3c414504a78adb24078eec818a0', 'https://tinyurl.com/264j5aa6infra_hash=67100b0ab7a52ad8e5d365a7a036711626ee457dbb7de12cda2bcfcbd865a3a1', 'https://tinyurl.com/245dqwsginfra_hash=a2fbcc1a7a0aa9191c8820c570c97d86796c45543783a89cefb3f877fd0c5155', 'https://tinyurl.com/22bd7takinfra_hash=ef8de679d05413fa90ff667668405e8ade480bfbf4eeb855ccac1ab2c8e5af68']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749', 'https://tinyurl.com/2268fmdqinfra_hash=98c74b0b38ca33ec7b6a01440a9243ab5eb9b3c414504a78adb24078eec818a0', 'https://tinyurl.com/264j5aa6infra_hash=67100b0ab7a52ad8e5d365a7a036711626ee457dbb7de12cda2bcfcbd865a3a1', 'https://tinyurl.com/245dqwsginfra_hash=a2fbcc1a7a0aa9191c8820c570c97d86796c45543783a89cefb3f877fd0c5155', 'https://tinyurl.com/22bd7takinfra_hash=ef8de679d05413fa90ff667668405e8ade480bfbf4eeb855ccac1ab2c8e5af68', 'https://tinyurl.com/24ndwoxsinfra_hash=2c76a1ecd0537558cc2a115b9937f9e5e39c5374f73917649836fd8762629d36']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749', 'https://tinyurl.com/2268fmdqinfra_hash=98c74b0b38ca33ec7b6a01440a9243ab5eb9b3c414504a78adb24078eec818a0', 'https://tinyurl.com/264j5aa6infra_hash=67100b0ab7a52ad8e5d365a7a036711626ee457dbb7de12cda2bcfcbd865a3a1', 'https://tinyurl.com/245dqwsginfra_hash=a2fbcc1a7a0aa9191c8820c570c97d86796c45543783a89cefb3f877fd0c5155', 'https://tinyurl.com/22bd7takinfra_hash=ef8de679d05413fa90ff667668405e8ade480bfbf4eeb855ccac1ab2c8e5af68', 'https://tinyurl.com/24ndwoxsinfra_hash=2c76a1ecd0537558cc2a115b9937f9e5e39c5374f73917649836fd8762629d36', 'https://tinyurl.com/25l9zwepinfra_hash=c160c80db8585424271391dc48da79aac6b48fd4ae825e2e96ef4e310b14d48f']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749', 'https://tinyurl.com/2268fmdqinfra_hash=98c74b0b38ca33ec7b6a01440a9243ab5eb9b3c414504a78adb24078eec818a0', 'https://tinyurl.com/264j5aa6infra_hash=67100b0ab7a52ad8e5d365a7a036711626ee457dbb7de12cda2bcfcbd865a3a1', 'https://tinyurl.com/245dqwsginfra_hash=a2fbcc1a7a0aa9191c8820c570c97d86796c45543783a89cefb3f877fd0c5155', 'https://tinyurl.com/22bd7takinfra_hash=ef8de679d05413fa90ff667668405e8ade480bfbf4eeb855ccac1ab2c8e5af68', 'https://tinyurl.com/24ndwoxsinfra_hash=2c76a1ecd0537558cc2a115b9937f9e5e39c5374f73917649836fd8762629d36', 'https://tinyurl.com/25l9zwepinfra_hash=c160c80db8585424271391dc48da79aac6b48fd4ae825e2e96ef4e310b14d48f', 'https://tinyurl.com/2xjvht7linfra_hash=c89134b9fae3a86fd93f85ffcd8d807c4ec9f73d54a7747289837a71bf624c1d']\n",
      "['https://tinyurl.com/28g5p9uvinfra_hash=619eda36e48c159143a49eaabdf96986d4a0e2a7e9d0f8cdb846c171a62f24bb', 'https://tinyurl.com/25mjxhm7infra_hash=70e011f416e06cbdf51778c58835638843bb8ecbce0b8776621edc3794c53749', 'https://tinyurl.com/2268fmdqinfra_hash=98c74b0b38ca33ec7b6a01440a9243ab5eb9b3c414504a78adb24078eec818a0', 'https://tinyurl.com/264j5aa6infra_hash=67100b0ab7a52ad8e5d365a7a036711626ee457dbb7de12cda2bcfcbd865a3a1', 'https://tinyurl.com/245dqwsginfra_hash=a2fbcc1a7a0aa9191c8820c570c97d86796c45543783a89cefb3f877fd0c5155', 'https://tinyurl.com/22bd7takinfra_hash=ef8de679d05413fa90ff667668405e8ade480bfbf4eeb855ccac1ab2c8e5af68', 'https://tinyurl.com/24ndwoxsinfra_hash=2c76a1ecd0537558cc2a115b9937f9e5e39c5374f73917649836fd8762629d36', 'https://tinyurl.com/25l9zwepinfra_hash=c160c80db8585424271391dc48da79aac6b48fd4ae825e2e96ef4e310b14d48f', 'https://tinyurl.com/2xjvht7linfra_hash=c89134b9fae3a86fd93f85ffcd8d807c4ec9f73d54a7747289837a71bf624c1d', 'https://tinyurl.com/25nx5coninfra_hash=21ac6b8c8d3794c791ec20dbabb13091dbc370b5fe6dfc111a0f8593d1c306c1']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m dados_consolidados \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()  \u001b[38;5;66;03m# DataFrame vazio para acumular os dados\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Extrair os dados da página atual e adicionar ao DataFrame consolidado\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_pagina \u001b[38;5;241m=\u001b[39m \u001b[43mextrair_dados\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m dados_consolidados \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([dados_consolidados, df_pagina], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Procurar o botão \"Próxima\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 77\u001b[0m, in \u001b[0;36mextrair_dados\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Organizando os dados para o DataFrame\u001b[39;00m\n\u001b[0;32m     67\u001b[0m dados \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNúmero do Processo\u001b[39m\u001b[38;5;124m\"\u001b[39m: trees[::\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumento\u001b[39m\u001b[38;5;124m\"\u001b[39m: trees[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinks\u001b[39m\u001b[38;5;124m\"\u001b[39m: links_curtos\n\u001b[0;32m     75\u001b[0m }\n\u001b[1;32m---> 77\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdados\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32md:\\Daiana Sales\\aspar\\aspar_venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32md:\\Daiana Sales\\aspar\\aspar_venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Daiana Sales\\aspar\\aspar_venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32md:\\Daiana Sales\\aspar\\aspar_venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "dados_consolidados = pd.DataFrame()  # DataFrame vazio para acumular os dados\n",
    "\n",
    "# Extrair os dados da página atual e adicionar ao DataFrame consolidado\n",
    "df_pagina = extrair_dados(driver)\n",
    "dados_consolidados = pd.concat([dados_consolidados, df_pagina], ignore_index=True)\n",
    "# Procurar o botão \"Próxima\"\n",
    "next_page = driver.find_element(\"xpath\", '//*[@id=\"conteudo\"]/div[2]/div[3]/a')\n",
    "proxima_href = next_page.get_attribute('href')\n",
    "print(proxima_href)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navegar_paginas(driver):\n",
    "    \"\"\"\n",
    "    Loop para navegar por todas as páginas até que não haja mais um botão 'Próxima'.\n",
    "    Retorna um DataFrame consolidado com os dados de todas as páginas.\n",
    "    \"\"\"\n",
    "    dados_consolidados = pd.DataFrame()  # DataFrame vazio para acumular os dados\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Extrair os dados da página atual e adicionar ao DataFrame consolidado\n",
    "            df_pagina = extrair_dados(driver)\n",
    "            dados_consolidados = pd.concat([dados_consolidados, df_pagina], ignore_index=True)\n",
    "\n",
    "            # Procurar o botão \"Próxima\"\n",
    "            next_page = driver.find_element(\"xpath\", '//*[@id=\"conteudo\"]/div[2]/div[3]/a')\n",
    "\n",
    "            # Verificar se o botão \"Próxima\" tem o atributo 'href'\n",
    "            proxima_href = next_page.get_attribute('href')\n",
    "            print(proxima_href)\n",
    "            time.sleep(3)\n",
    "            if not proxima_href:\n",
    "                print(\"Não há mais páginas. Encerrando navegação.\")\n",
    "                break  # Sai do loop se não houver link para a próxima página\n",
    "\n",
    "            # Clicar no botão \"Próxima\"\n",
    "            next_page.click()\n",
    "            time.sleep(10)  # Aguarda o carregamento da próxima página\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(\"Botão 'Próxima' não encontrado. Encerrando navegação.\")\n",
    "            break  # Sai do loop se o botão \"Próxima\" não existir\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro inesperado: {e}\")\n",
    "            break  # Sai do loop em caso de erro inesperado\n",
    "\n",
    "    # Fechar o navegador após o término\n",
    "    # driver.close()\n",
    "    # driver.quit()\n",
    "\n",
    "    return dados_consolidados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = navegar_paginas(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "def gerar_excel(df):\n",
    "    output = BytesIO()\n",
    "    with pd.ExcelWriter(output, engine=\"xlsxwriter\") as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=\"Doc_SEI\")\n",
    "    processed_data = output.getvalue()\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data = gerar_excel(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(excel_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspar_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
